# Monitoring Stack - Prometheus + Grafana

Kompletny monitoring klastra K3s z automatycznÄ… detekcjÄ… i alertami.

## Komponenty

### 1. Prometheus
- **Port:** 30090
- **Rola:** Zbieranie i przechowywanie metryk
- **Retencja:** 15 dni
- **Storage:** 10Gi PVC

**Co monitoruje:**
- âœ… Kubernetes API Server
- âœ… Node metrics (kubelet, cadvisor)
- âœ… Container metrics
- âœ… Pod metrics
- âœ… Service endpoints
- âœ… Node Exporter metrics (system)
- âœ… kube-state-metrics (K8s objects)

### 2. Grafana
- **Port:** 30300
- **Login:** admin / admin (ZMIEÅƒ!)
- **Datasource:** Prometheus (auto-configured)
- **Storage:** 2Gi PVC

**Features:**
- Gotowy datasource do Prometheus
- Import dashboardÃ³w przez ID
- Persistent storage dla dashboardÃ³w

### 3. Node Exporter
- **Type:** DaemonSet (jeden pod na kaÅ¼dym node)
- **Port:** 9100
- **Auto-discovery:** Tak

**Metryki:**
- CPU usage per core
- Memory (used, available, cached)
- Disk I/O i przestrzeÅ„
- Network traffic
- Load average
- File descriptors
- Inne system metrics

### 4. kube-state-metrics
- **Port:** 8080
- **Rola:** Eksponuje stan obiektÃ³w Kubernetes

**Metryki:**
- Deployments status
- Pods status (running, pending, failed)
- Node conditions
- Resource quotas
- Persistent volumes
- ConfigMaps, Secrets (count)

### 5. AlertManager
- **Port:** 30093
- **Rola:** ZarzÄ…dzanie alertami
- **Config:** Routing, grouping, inhibition

## DostÄ™p

```bash
# Po deployu
export KUBECONFIG=$(pwd)/kubeconfig

# URLs (zastÄ…p MASTER_IP)
Prometheus:   http://MASTER_IP:30090
Grafana:      http://MASTER_IP:30300
AlertManager: http://MASTER_IP:30093

# Lub uÅ¼yj Makefile
make grafana  # PokaÅ¼e wszystkie info
```

## Grafana - Quick Start

### 1. Pierwsze logowanie

```bash
# OtwÃ³rz w przeglÄ…darce
http://MASTER_IP:30300

# Login
Username: admin
Password: admin

# âš ï¸ ZmieÅ„ hasÅ‚o przy pierwszym logowaniu!
```

### 2. Zaimportuj Dashboardy

Grafana umoÅ¼liwia import gotowych dashboardÃ³w przez ID:

**Polecane dashboardy:**

| ID | Nazwa | Opis |
|----|-------|------|
| **1860** | Node Exporter Full | Kompletne metryki systemowe |
| **7249** | Kubernetes Cluster Monitoring | PrzeglÄ…d klastra K8s |
| **315** | Kubernetes Cluster (Prometheus) | Alternatywny dashboard klastra |
| **12114** | Kubernetes Pods | SzczegÃ³Å‚owe metryki podÃ³w |
| **6417** | Kubernetes Cluster (Prometheus) | Bardzo szczegÃ³Å‚owy |

**Jak zaimportowaÄ‡:**

1. W Grafana: **Dashboards â†’ Import**
2. Wpisz ID (np. `1860`)
3. Kliknij **Load**
4. Wybierz datasource: **Prometheus**
5. Kliknij **Import**

### 3. Gotowe Dashboardy

Po zaimportowaniu znajdziesz:

**Node Exporter Full (1860):**
- CPU usage per core + Å›rednia
- Memory usage (used, cached, buffers)
- Disk I/O operations
- Network traffic (RX/TX)
- Load average (1m, 5m, 15m)
- Disk space per filesystem
- System uptime

**Kubernetes Cluster Monitoring (7249):**
- Nodes status i resources
- Pods running/pending/failed
- CPU/Memory requests vs limits
- Namespace resource usage
- Top pods by CPU/Memory
- Network I/O per pod

## Prometheus Queries (PromQL)

### PrzykÅ‚ady podstawowych query:

```promql
# CPU usage per node
100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Memory usage per node
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100

# Disk space usage
(node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes * 100

# Pod count per namespace
count by (namespace) (kube_pod_info)

# Pods not running
count(kube_pod_status_phase{phase!="Running"})

# Container restarts
rate(kube_pod_container_status_restarts_total[5m])

# Top 5 pods by CPU
topk(5, rate(container_cpu_usage_seconds_total[5m]))

# Top 5 pods by Memory
topk(5, container_memory_usage_bytes)
```

### Testowanie Query

1. OtwÃ³rz Prometheus: http://MASTER_IP:30090
2. Kliknij **Graph**
3. Wpisz query w polu
4. Kliknij **Execute**
5. Zobacz wyniki (Graph lub Table)

## Alerty

### Skonfigurowane Alerty

**Node Alerts:**
- âš ï¸ `NodeDown` - Node nie odpowiada > 2 min (critical)
- âš ï¸ `HighCPUUsage` - CPU > 80% przez 5 min (warning)
- âš ï¸ `HighMemoryUsage` - Memory > 85% przez 5 min (warning)
- âš ï¸ `DiskSpaceLow` - Disk < 15% przez 5 min (warning)

**Kubernetes Alerts:**
- âš ï¸ `PodCrashLooping` - Pod restartuje siÄ™ czÄ™sto (warning)
- âš ï¸ `PodNotReady` - Pod nie jest Ready > 10 min (warning)
- âš ï¸ `DeploymentReplicasMismatch` - Replicas != desired > 10 min (warning)

### Sprawdzenie AlertÃ³w

**W Prometheus:**
```
http://MASTER_IP:30090/alerts
```

**W AlertManager:**
```
http://MASTER_IP:30093
```

### Konfiguracja PowiadomieÅ„

DomyÅ›lnie alerty tylko logujÄ…. Aby dodaÄ‡ powiadomienia (email, Slack, webhook):

```bash
# Edytuj AlertManager config
kubectl edit configmap alertmanager-config -n monitoring

# PrzykÅ‚ad - Slack webhook
receivers:
  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
        channel: '#alerts'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

# Apply zmian
kubectl rollout restart deployment alertmanager -n monitoring
```

## Troubleshooting

### Prometheus nie zbiera metryk

```bash
# SprawdÅº targets
# OtwÃ³rz: http://MASTER_IP:30090/targets
# Wszystkie powinny byÄ‡ "UP"

# JeÅ›li sÄ… "DOWN", sprawdÅº logi
kubectl logs -n monitoring -l app=prometheus

# SprawdÅº konfiguracjÄ™
kubectl get configmap prometheus-config -n monitoring -o yaml
```

### Node Exporter nie dziaÅ‚a

```bash
# SprawdÅº DaemonSet
kubectl get ds -n monitoring node-exporter

# Powinno byÄ‡ 3/3 (jeden pod na node)
# JeÅ›li nie, sprawdÅº logi
kubectl logs -n monitoring -l app=node-exporter

# Test rÄ™czny (z mastera)
curl http://NODE_IP:9100/metrics
```

### Grafana nie Å‚Ä…czy siÄ™ z Prometheus

```bash
# SprawdÅº datasource w Grafana
# Settings â†’ Data Sources â†’ Prometheus
# Test Connection

# SprawdÅº czy Prometheus odpowiada
kubectl exec -n monitoring -it deployment/grafana -- \
  wget -O- http://prometheus:9090/api/v1/query?query=up

# Restart Grafany
kubectl rollout restart deployment grafana -n monitoring
```

### Brak danych na dashboardach

```bash
# SprawdÅº czy sÄ… metryki w Prometheus
# http://MASTER_IP:30090/graph
# Query: up
# Powinno pokazaÄ‡ wszystkie targety

# SprawdÅº time range w Grafana (prawy gÃ³rny rÃ³g)
# Ustaw "Last 5 minutes" lub "Last 15 minutes"

# OdÅ›wieÅ¼ dashboard (Ctrl+R lub przycisk refresh)
```

### Dashboard "No data"

**MoÅ¼liwe przyczyny:**
1. ZÅ‚y datasource - wybierz "Prometheus"
2. Brak metryk - sprawdÅº czy Node Exporter dziaÅ‚a
3. ZÅ‚y time range - ustaw na "Last 15 minutes"
4. Query error - sprawdÅº logi w Query Inspector

**Fix:**
```bash
# SprawdÅº czy sÄ… metryki
kubectl exec -n monitoring deployment/prometheus -- \
  wget -qO- localhost:9090/api/v1/query?query=up

# Restart wszystkich komponentÃ³w
kubectl rollout restart deployment -n monitoring
```

## Best Practices

### 1. ZmieÅ„ hasÅ‚o Grafana

```bash
# W Grafana UI
Settings â†’ Profile â†’ Change Password

# Lub przez kubectl
kubectl exec -n monitoring deployment/grafana -- \
  grafana-cli admin reset-admin-password NOWE_HASLO
```

### 2. Backup dashboardÃ³w

```bash
# Export dashboardu (z Grafana UI)
Dashboard Settings â†’ JSON Model â†’ Copy

# Lub backup caÅ‚ego storage
kubectl exec -n monitoring deployment/grafana -- \
  tar -czf /tmp/grafana-backup.tar.gz /var/lib/grafana
kubectl cp monitoring/grafana-xxx:/tmp/grafana-backup.tar.gz ./grafana-backup.tar.gz
```

### 3. ZwiÄ™ksz retencjÄ™ Prometheus

```bash
# Edytuj deployment
kubectl edit deployment prometheus -n monitoring

# ZmieÅ„ arg:
- '--storage.tsdb.retention.time=15d'
# Na np.:
- '--storage.tsdb.retention.time=30d'

# ZwiÄ™ksz PVC jeÅ›li potrzeba
kubectl edit pvc prometheus-storage -n monitoring
```

### 4. Dodaj custom metryki

**Dla aplikacji z endpoint /metrics:**

```yaml
# Dodaj annotation do poda
apiVersion: v1
kind: Pod
metadata:
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
```

Prometheus automatycznie wykryje i zacznie scrape'owaÄ‡!

## Metryki do Å›ledzenia

### Dla stabilnoÅ›ci:
- âœ… Node CPU/Memory usage
- âœ… Disk space remaining
- âœ… Pod restart count
- âœ… Pods not ready
- âœ… API server latency

### Dla performance:
- âœ… Container CPU throttling
- âœ… Memory OOM kills
- âœ… Network errors/drops
- âœ… Disk I/O latency

### Dla capacity planning:
- âœ… Resource requests vs actual usage
- âœ… Storage growth trend
- âœ… Pod count trend
- âœ… Network bandwidth usage

## Przydatne Linki

- [PromQL Documentation](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Grafana Dashboards](https://grafana.com/grafana/dashboards/)
- [Node Exporter](https://github.com/prometheus/node_exporter)
- [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)

## Na Rozmowie Rekrutacyjnej

**MoÅ¼esz powiedzieÄ‡:**

> "ZaimplementowaÅ‚em kompletny monitoring stack z Prometheus i Grafana.
> Prometheus automatycznie wykrywa wszystkie komponenty Kubernetes przez
> service discovery i zbiera metryki z Node Exporter (system metrics) oraz
> kube-state-metrics (K8s objects). SkonfigurowaÅ‚em alerty dla krytycznych
> scenariuszy jak high CPU, low disk space czy pod crash looping.
>
> W Grafana mam zaimportowane standardowe dashboardy pokazujÄ…ce metryki
> na poziomie node'Ã³w, podÃ³w i caÅ‚ego klastra. Wszystko jest persistent
> i dziaÅ‚a out-of-the-box po deployment."

**To pokazuje Å¼e:**
- âœ… Rozumiesz monitoring w Kubernetes
- âœ… Znasz Prometheus + Grafana
- âœ… Potrafisz konfigurowaÄ‡ alerty
- âœ… MyÅ›lisz o observability

**Bonus points:** PokaÅ¼ live dashboard podczas rozmowy! ğŸ¯
